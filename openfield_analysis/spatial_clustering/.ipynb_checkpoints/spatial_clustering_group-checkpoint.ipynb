{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmarshall/anaconda3/envs/caiman/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.decomposition.incremental_pca module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/johnmarshall/anaconda3/envs/caiman/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/johnmarshall/anaconda3/envs/caiman/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/johnmarshall/anaconda3/envs/caiman/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/johnmarshall/anaconda3/envs/caiman/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/johnmarshall/anaconda3/envs/caiman/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/johnmarshall/anaconda3/envs/caiman/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio\n",
    "from scipy import stats\n",
    "from importlib import reload\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "#sys.path.append('/home/jma819/post_cmfe_analysis')\n",
    "sys.path.append('/Users/johnmarshall/Documents/Analysis/PythonAnalysisScripts/post_cmfe_analysis')\n",
    "import python_utils_jjm as utils_jjm\n",
    "import dlc_utils\n",
    "import caiman\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.spatial.distance as dist\n",
    "import itertools\n",
    "import math\n",
    "import warnings\n",
    "import numbers\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dlc_utils' from '/Users/johnmarshall/Documents/Analysis/PythonAnalysisScripts/post_cmfe_analysis/dlc_utils.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(utils_jjm)\n",
    "reload(dlc_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmfe_file_key = pd.read_csv('/volumes/My_Passport/dlc_analysis/behavcamvideos/cnmfe_file_key.csv')\n",
    "#cnmfe_file_key = pd.read_csv('/projects/p30771/dlc_analysis/openfield_dlc_output/cnmfe_file_key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmfe_base_dir = '/Volumes/My_Passport/cnmfe_analysis_files/batch_output_files/'\n",
    "#cnmfe_base_dir = '/projects/p30771/MATLAB/CNMF_E_jjm/quest_MATLAB_cnmfe/batch_output_files/'\n",
    "wt_CNMFE_file = ['30-Mar_20_39_05_out.mat', '30-Mar_20_45_16_out.mat', '27-Feb_17_33_59_out.mat', '22-Mar_22_52_02_out.mat',\n",
    "                 '28-Feb_16_10_05_out.mat', '27-Feb_17_32_15_out.mat', '28-Feb_16_21_21_out.mat', '25-Mar_13_27_27_out.mat',\n",
    "                 '25-Mar_14_22_02_out.mat', '25-Mar_14_22_44_out.mat', '26-Mar_18_33_55_out.mat', '27-Mar_00_26_12_out.mat', '27-Mar_00_48_46_out.mat']\n",
    "\n",
    "ko_CNMFE_files = ['31-Mar_13_28_15_out.mat', '29-Mar_21_42_20_out.mat', '13-Apr_17_57_40_out.mat', '29-Mar_14_27_55_out.mat', '13-Apr_16_01_20_out.mat',\n",
    "                 '13-Apr_16_11_27_out.mat', '29-Mar_13_39_44_out.mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_files = ['/volumes/My_Passport/dlc_analysis/behavcamvideos/'+utils_jjm.find_behavior_tracking(fname, cnmfe_file_key) for fname in wt_CNMFE_file] \n",
    "#tracking_files = ['/projects/p30771/dlc_analysis/openfield_dlc_output/'+utils_jjm.find_behavior_tracking(fname, cnmfe_file_key) for fname in wt_CNMFE_file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNMFE_dir_paths_list = [str(cnmfe_base_dir+fname) for fname in wt_CNMFE_file]\n",
    "#CNMFE_dir_paths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_time = 1 # seconds \n",
    "body_part_for_tracking = 'tail_base' #\n",
    "number_of_bins = 50 #\n",
    "polynomial_degree = 2 #\n",
    "\n",
    "grouped_raw_data = {}\n",
    "success = []\n",
    "failed = []\n",
    "for CNMFE_file, tracking_file in zip(CNMFE_dir_paths_list, tracking_files):\n",
    "    #print(CNMFE_file)\n",
    "    #print(tracking_file)\n",
    "    try:\n",
    "        # load cell fluorescence \n",
    "        cell_fluorescence = sio.loadmat(CNMFE_file)\n",
    "        C_timedelta = utils_jjm.create_fluorescence_time_delta(cell_fluorescence['C'])\n",
    "        C_normalized = C_timedelta.apply(utils_jjm.normalize).set_index(pd.to_timedelta(np.linspace(0, (len(C_timedelta)-1)*(1/20), len(C_timedelta)), unit='s'), drop=True)\n",
    "        C_z_scored = C_timedelta.apply(stats.zscore).set_index(pd.to_timedelta(np.linspace(0, (len(C_timedelta)-1)*(1/20), len(C_timedelta)), unit='s'), drop=True)\n",
    "        C_normalized_z_scored = C_normalized.apply(stats.zscore).set_index(pd.to_timedelta(np.linspace(0, (len(C_normalized)-1)*(1/20), len(C_normalized)), unit='s'), drop=True)\n",
    "        # create tracking time deltas\n",
    "        interpolated = utils_jjm.prepare_timedelta_dfs(tracking_file)\n",
    "        #load spatial components by session\n",
    "        com_df, spatial_components = utils_jjm.return_spatial_info(CNMFE_file, 0.6)\n",
    "        cell_contours, for_dims = utils_jjm.create_contour_layouts(spatial_components)\n",
    "        #C_z_scored_filtered = utils_jjm.filter_out_by_size(C_z_scored, cell_contours, for_dims, 0.6, 100)\n",
    "        #store results \n",
    "        grouped_raw_data[tracking_file.split('/')[-2]] = {'C': C_timedelta, 'C_z_scored': C_z_scored, 'C_normalized': C_normalized, 'C_normalized_z_scored': C_normalized_z_scored, \n",
    "                                                          'interpolated' : interpolated, 'com' : com_df, 'spatial_components' : spatial_components, 'cell_contours': cell_contours,  \n",
    "                                                         'for_dims' : for_dims}\n",
    "        success.append((tracking_file.split('/')[-2], CNMFE_file.split('/')[-1]))\n",
    "    except FileNotFoundError:\n",
    "        failed.append(tracking_file)\n",
    "    except OSError:\n",
    "        failed.append(tracking_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spatial clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine dfs for each session to bin velocity values across dfs\n",
    "#downsample\n",
    "new_sampling_interval = .2\n",
    "V_df = pd.concat([grouped_raw_data[session]['interpolated'].resample(str(new_sampling_interval)+'S').max() \n",
    "                  for session in list(grouped_raw_data.keys())], keys=list(grouped_raw_data.keys()))\n",
    "all_sessions_v_bins = pd.cut(V_df['tail_base'], bins=50)\n",
    "\n",
    "V_df['velocity_bins'] = all_sessions_v_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and filter fluorescence\n",
    "filtered_for_analysis = {}\n",
    "for session in list(grouped_raw_data.keys()):\n",
    "    filtered_for_analysis[session] = utils_jjm.filter_out_by_size(grouped_raw_data[session]['C_normalized_z_scored'], grouped_raw_data[session]['cell_contours'], \n",
    "                                                                  grouped_raw_data[session]['for_dims'], 0.6, 100)\n",
    "C_df = pd.concat([filtered_for_analysis[session].resample(str(new_sampling_interval)+'S').max()\n",
    "                  for session in list(grouped_raw_data.keys())], keys=list(grouped_raw_data.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|▊         | 1/13 [00:02<00:24,  2.00s/it]\u001b[A\n",
      " 15%|█▌        | 2/13 [00:04<00:23,  2.18s/it]\u001b[A\n",
      " 23%|██▎       | 3/13 [00:09<00:30,  3.02s/it]\u001b[A\n",
      " 31%|███       | 4/13 [00:11<00:23,  2.62s/it]\u001b[A\n",
      " 38%|███▊      | 5/13 [00:19<00:33,  4.18s/it]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:29<00:41,  5.92s/it]\u001b[A\n",
      " 54%|█████▍    | 7/13 [00:38<00:41,  6.95s/it]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:41<00:28,  5.79s/it]\u001b[A\n",
      " 69%|██████▉   | 9/13 [00:43<00:18,  4.72s/it]\u001b[A\n",
      " 77%|███████▋  | 10/13 [00:46<00:12,  4.01s/it]\u001b[A\n",
      " 85%|████████▍ | 11/13 [00:53<00:10,  5.10s/it]\u001b[A\n",
      " 92%|█████████▏| 12/13 [00:59<00:05,  5.42s/it]\u001b[A\n",
      "100%|██████████| 13/13 [01:06<00:00,  5.11s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# clustering info per session \n",
    "coactivity_dfs = {}\n",
    "for session in tqdm(list(grouped_raw_data.keys())):\n",
    "    # get indicies of small cells \n",
    "    cells_to_drop = np.array([cell for cell in range(1, len(grouped_raw_data[session]['cell_contours'])+1) if \n",
    "                              len(np.array(np.where(grouped_raw_data[session]['for_dims'][cell]>0.6)[0]))<100])\n",
    "    #compile and filter cell centers of mass\n",
    "    filtered_centers_of_mass = grouped_raw_data[session]['com'].drop(cells_to_drop, axis =0)\n",
    "\n",
    "    com_distances = utils_jjm.get_pairwise_distance_by_session(filtered_centers_of_mass)\n",
    "\n",
    "    ##get binned fluorescence and calc Jaccard scores\n",
    "    #arguments are sample widths to bin and z score threshold\n",
    "    cells_in_session = C_df.loc[session].dropna(axis=1).drop('msCamFrame', axis=1)\n",
    "    binned_fluorescence = cells_in_session.apply(utils_jjm.binning_function_uncrop, args=[1, 2])\n",
    "\n",
    "    reindexed = binned_fluorescence.set_index(int(x) for x in np.linspace(0, len(binned_fluorescence)-1, len(binned_fluorescence)))\n",
    "\n",
    "    #ks_results_2sided, ks_one_sided_more, ks_one_sided_less, coactivity_dfs = utils_jjm.spatial_coordination_by_session(reindexed, 10, com_distances)\n",
    "    coactivity_dfs[session] = utils_jjm.spatial_coordination_by_session(reindexed)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6250"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reindexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">33</th>\n",
       "      <th colspan=\"3\" halign=\"left\">34</th>\n",
       "      <th colspan=\"2\" halign=\"left\">35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coactivity</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1                              ... 33          34       35    36\n",
       "           2  3  4  6  7  8  9  10 11 12  ... 34 35 36 37 35 36 37 36 37 37\n",
       "coactivity  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "[1 rows x 630 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coactivity_dfs['GRIN013_H13_M33_S54'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session='GRIN013_H13_M33_S54'\n",
    "\n",
    "cells_to_drop = np.array([cell for cell in range(1, len(grouped_raw_data[session]['cell_contours'])+1) if \n",
    "                              len(np.array(np.where(grouped_raw_data[session]['for_dims'][cell]>0.6)[0]))<100])\n",
    "filtered_centers_of_mass = grouped_raw_data[session]['com'].drop(cells_to_drop, axis =0)\n",
    "\n",
    "pairwise_distance = utils_jjm.get_pairwise_distance_by_session(filtered_centers_of_mass)\n",
    "\n",
    "    ##get binned fluorescence and calc Jaccard scores\n",
    "    #arguments are sample widths to bin and z score thresholds\n",
    "cells_in_session = C_df.loc[session].dropna(axis=1).drop('msCamFrame', axis=1)\n",
    "binned_fluorescence = cells_in_session.apply(utils_jjm.binning_function_uncrop, args=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexed = binned_fluorescence.set_index(int(x) for x in np.linspace(0, len(binned_fluorescence)-1, len(binned_fluorescence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make following code work with these variables for function\n",
    "binnums = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ks_results_2sided = []\n",
    "ks_one_sided_more = []\n",
    "ks_one_sided_less = []\n",
    "\n",
    "time_points = tqdm(range(len(reindexed)))\n",
    "for time_index in time_points:\n",
    "    coactivity_by_time_point = {}\n",
    "    for pair in itertools.combinations(list(binned_fluorescence.columns), 2):\n",
    "        if (reindexed.loc[time_index][pair[0]] == 1) and (reindexed.loc[time_index][pair[1]] == 1):\n",
    "            coactivity_by_time_point[pair] = 1\n",
    "        else:\n",
    "            coactivity_by_time_point[pair] = 0\n",
    "    coactivity_df = pd.DataFrame(coactivity_by_time_point, index=['coactivity'])\n",
    "\n",
    "    coactive_cell_distances = pairwise_distance[coactivity_df[coactivity_df == 1].dropna(axis=1).columns]\n",
    "    non_coactive_distances = pairwise_distance[coactivity_df[coactivity_df == 0].dropna(axis=1).columns]\n",
    "\n",
    "    #linear_distribution = np.linspace(1, len(coactive_cell_distances.columns), binnums)\n",
    "\n",
    "    #binnums=10\n",
    "    cum_results_coactive = stats.cumfreq(coactive_cell_distances.values[0], numbins=binnums, defaultreallimits=(0, 500))\n",
    "    cum_results_non_coactive = stats.cumfreq(non_coactive_distances.values[0], numbins=binnums, defaultreallimits=(0, 500))\n",
    "\n",
    "    #plt.plot(np.linspace(0, 500, binnums), cum_results_coactive.cumcount/len(coactive_cell_distances.values[0]))\n",
    "    #plt.plot(np.linspace(0, 500, binnums), cum_results_non_coactive.cumcount/len(non_coactive_distances.values[0]))\n",
    "    #plt.plot(np.linspace(0, 500, binnums), linear_distribution/len(coactive_cell_distances.values[0]))\n",
    "    #plt.show()\n",
    "\n",
    "    less_result = stats.kstest(cum_results_coactive.cumcount/len(coactive_cell_distances.values[0]), 'norm', alternative='less')\n",
    "    more_result = stats.kstest(cum_results_coactive.cumcount/len(coactive_cell_distances.values[0]), 'norm', alternative='more')\n",
    "    ks_one_sided_more.append(more_result)\n",
    "    ks_one_sided_less.append(less_result)\n",
    "    \n",
    "    #coordination_index = utils_jjm.create_coordination_index(more_result, less_result)\n",
    "\n",
    "    #two sided test between coactive and noncoactive distribution \n",
    "    ks_result = stats.ks_2samp(cum_results_coactive.cumcount/len(coactive_cell_distances.values[0]), cum_results_non_coactive.cumcount/len(non_coactive_distances.values[0]))\n",
    "    #coordination_indicies.append(coordination_index)\n",
    "    ks_results_2sided.append(ks_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for plotting average spatial coordination during trigger regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "triggered_activity_across_sessions = {}\n",
    "for session in list(grouped_raw_data.keys()):\n",
    "    #inputs activity_threshold, resting_threshold, resting_baseline \n",
    "    crossing_indicies = utils_jjm.select_trigger_regions(binned_velocity_df[session], 0.5, 0.5, 20)\n",
    "    #inputs time_to_plot\n",
    "    threshold_activity = utils_jjm.average_triggered_regions(V_df.loc[session]['tail_base'].values, crossing_indicies, 40)\n",
    "    \n",
    "    f_threshold_activity = utils_jjm.average_triggered_regions(spatial_coordination_activity_in_session \n",
    "            , crossing_indicies, 40)\n",
    "    triggered_activity_across_sessions[session] = pd.concat([threshold_activity, f_threshold_activity], axis=1, keys=['velocity', 'spatial_coordination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#triggered_activity_across_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat by mouse \n",
    "concacted_by_mouse = {}\n",
    "for mouse in list(set([session[0:7] for session in list(triggered_activity_across_sessions.keys())])):\n",
    "    dfs_by_mouse = []\n",
    "    sessions = []\n",
    "    for session in list(triggered_activity_across_sessions.keys()):\n",
    "        if mouse in session:\n",
    "            if not(triggered_activity_across_sessions[session].empty):\n",
    "                means = triggered_activity_across_sessions[session].mean(axis=1, level=0)\n",
    "                dfs_by_mouse.append(means)\n",
    "                sessions.append(session)\n",
    "    if len(dfs_by_mouse)>0:\n",
    "        concacted_by_mouse[mouse] = pd.concat(dfs_by_mouse, axis=1, keys=sessions)\n",
    "combined_by_mouse = pd.concat(list(concacted_by_mouse.values()), axis=1, keys=list(concacted_by_mouse.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_by_mouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-40*.2, 40*.2, 80)\n",
    "mean=combined_by_mouse.mean(axis=1, level=2)['velocity'].values\n",
    "plt.plot(x, combined_by_mouse.mean(axis=1, level=2)['velocity'].values, color='k')\n",
    "std_error = (combined_by_mouse.std(axis=1, level=2)['velocity'])/math.sqrt(combined_by_mouse.mean(axis=1, level=0).shape[1])\n",
    "plt.fill_between(x, mean-std_error, mean+std_error)\n",
    "ax = plt.gca()\n",
    "ax.axvline(x=(0), linestyle='--', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-40*.2, 40*.2, 80)\n",
    "mean = combined_by_mouse.mean(axis=1, level=2)['fluorescence'].values\n",
    "plt.plot(x, mean, color='k')\n",
    "std_error = (combined_by_mouse.std(axis=1, level=2)['fluorescence'])/math.sqrt(combined_by_mouse.mean(axis=1, level=0).shape[1])\n",
    "plt.fill_between(x, mean-std_error, mean+std_error)\n",
    "ax = plt.gca()\n",
    "ax.axvline(x=0, linestyle='--', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "caiman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
